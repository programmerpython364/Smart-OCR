# Smart OCR: AI-Powered Media Processing Toolkit

![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![Flask](https://img.shields.io/badge/Flask-2.0%2B-green)
![AI](https://img.shields.io/badge/AI-Gemini--1.5--Flash-orange)

An intelligent web application for extracting and enhancing text from images and videos using state-of-the-art OCR and generative AI.

## Key Features âœ¨

- **Image & Video OCR**: Extract text from uploaded images (PNG, JPG, JPEG, WEBP) and videos (MP4).
- **AI-Powered Enhancement**: Refine extracted text using Google's Gemini LLM with conversational memory.
- **Frame Selection**: Choose specific video frames for text processing.
- **Session Management**: Automatic cleanup after 30 minutes of inactivity.
- **Error Reporting**: Detailed error pages with traceback for debugging.
- **Multi-Language Support**: Arabic/English OCR capabilities.


## Tech Stack ğŸ› ï¸

- **Backend**: Flask, LangChain
- **OCR**: EasyOCR
- **AI**: Google Gemini 1.5 Flash
- **Computer Vision**: OpenCV
- **Session Handling**: UUID-based user sessions


## ğŸ“¦ Installation

### âœ… Prerequisites
Ensure you have **Python 3.9+** installed. You also need `pip` to install dependencies.

### ğŸ“Œ Steps

1. **Clone the repository:**
   ```bash
   git clone https://github.com/3liodeh/Smart-OCR.git
   cd Smart-OCR
   ```

2. **Create a virtual environment and activate it:**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows use `venv\Scripts\activate`
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables:**
   - Create a `.env` file in the root directory and add:
     ```ini
     AI_API_TOKEN=your_api_key_here
     ```
   - Replace `your_api_key_here` with your **Google Gemini API key**.

5. **Run the application:**
   ```bash
   python app.py
   ```

6. **Access the application:**
   Open your browser and go to [`http://localhost:10000`](http://localhost:10000)

## ğŸ¯ Usage

### 1ï¸âƒ£ Upload an Image
- Navigate to `/image` and **upload an image**.
- The extracted text is displayed along with an option to **improve it using AI**.

### 2ï¸âƒ£ Upload a Video
- Navigate to `/video` and **upload a video** (`MP4`, max `20MB`).
- Select a frame to process **OCR** and improve extracted text.

### 3ï¸âƒ£ Chat with AI
- The `/chat` page allows users to **interact with the AI model** to refine extracted text.

## ğŸ“ File Structure

```plaintext
smart-ocr/
â”œâ”€â”€ model/                # OCR model
â”œâ”€â”€ app.py                # Flask application core
â”œâ”€â”€ LLM.py                # Gemini integration & memory
â”œâ”€â”€ OCR.py                # EasyOCR wrappers
â”œâ”€â”€ run.py                # Processing pipelines
â”œâ”€â”€ templates/            # Jinja2 templates
â”‚   â”œâ”€â”€ index.html        # Landing page
â”‚   â”œâ”€â”€ video.html        # video ORC interface
â”‚   â”œâ”€â”€ image.html        # image OCR interface
â”‚   â””â”€â”€ result.html       # Chat interface
â”œâ”€â”€ uploads/              # Ephemeral file storage
â”œâ”€â”€ requirements.txt      # Dependency list
â””â”€â”€ .env                  # API configuration
```

## ğŸ“œ Dependencies

Refer to `requirements.txt`:

```plaintext
Flask==2.2.5
werkzeug==2.2.3
easyocr==1.7.2
numpy==1.26.4
Pillow==10.3.0
opencv-python==4.9.0.80
python-dotenv==1.0.1
google-generativeai==0.8.4
langchain==0.3.17
langchain-core==0.3.33
```

## ğŸ“„ License

This project is licensed under the **MIT License**. Feel free to modify and use it as needed.

## ğŸ™ Acknowledgments

- **Google Gemini AI** for language modeling
- **EasyOCR** for text recognition
- **Flask** for web application framework
